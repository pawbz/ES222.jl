[{"url":"cheatsheets/","title":"Cheatsheets","tags":["welcome"],"text":"Cheatsheets Getting Started with Julia - live . Fastrack to Julia  cheatsheet. MATLAB-Julia-Python comparative cheatsheet  by  QuantEcon group Plots.jl cheatsheet"},{"url":"classes/","title":"Lecture Schedule","tags":["welcome"],"text":"main a img {\n    width: 5rem;\n    margin: 1rem;\n}\n Introduction of the course: inverse, learning and design problems Discrete Linear Inverse Problems Formulation of discrete linear inverse problem  Gm=d ; Row and column interpretations of matrix-vector  Gm  and matrix-matrix  GH  products Overdetermined and underdeterminded systems; Linear (in)dependence, basis vectors; independence-dimension inequality Left (right) inverses of a matrix with independent column (row) vectors; Gram matrix; pseudo inverses; solving linear equations with the inverses Solving inverse problems via matrix factorization;  CR  Column times Row and  QR  factorizations Example of fitting a polynomial using temperature anomaly data Example from seismic imaging: traveltime tomography"},{"url":".","title":"index","tags":["homepage"],"text":""},{"url":"installation/","title":"Software installation","tags":["welcome"],"text":"First-time setup: Install Julia & Pluto Text and pictures version: Step 1: Install Julia  1.8.2 Go to  https://julialang.org/downloads  and download the current stable release, Julia  1.8.2 , using the correct version for your operating system (Linux x86, Mac, Windows, etc). Step 2: Run Julia After installing,  make sure that you can run Julia . On some systems, this means searching for the “Julia  1.8.2 ” program installed on your computer; in others, it means running the command  julia  in a terminal. Make sure that you can execute  1 + 1 : Make sure that you are able to launch Julia and calculate  1+1  before proceeding! Step 3: Install  Pluto Next we will install the  Pluto , the notebook environment that we will be using during the course. Pluto is a Julia  programming environment  designed for interactivity and quick experiments. Open the  Julia REPL . This is the command-line interface to Julia, similar to the previous screenshot. Here you type  Julia commands , and when you press ENTER, it runs, and you see the result. To install Pluto, we want to run a  package manager command . To switch from  Julia  mode to  Pkg  mode, type  ]  (closing square bracket) at the  julia>  prompt: \njulia> ]\n\n(@v 1.8 ) pkg>\n The line turns blue and the prompt changes to  pkg> , telling you that you are now in  package manager mode . This mode allows you to do operations on  packages  (also called libraries). To install Pluto, run the following (case sensitive) command to  add  (install) the package to your system by downloading it from the internet.\nYou should only need to do this  once  for each installation of Julia: \n(@v 1.8 ) pkg> add Pluto\n This might take a couple of minutes, so you can go get yourself a cup of tea! You can now close the terminal. Step 4: Use a modern browser: Mozilla Firefox or Google Chrome We need a modern browser to view Pluto notebooks with. Firefox and Chrome work best. Second time:  Running Pluto & opening a notebook Repeat the following steps whenever you want to work on a project or homework assignment. Step 1: Start Pluto Start the Julia REPL, like you did during the setup. In the REPL, type: julia> using Pluto\n\njulia> Pluto.run()\n The terminal tells us to go to  http://localhost:1234/  (or a similar URL). Let’s open Firefox or Chrome and type that into the address bar. If you’re curious about what a  Pluto notebook  looks like, have a look at the  Featured Notebooks . These notebooks are useful for learning some basics of Julia programming. If you want to hear the story behind Pluto, have a look a the  JuliaCon presentation . If nothing happens in the browser the first time, close Julia and try again. And please let us know! Step 2a: Opening a notebook from the web This is the main menu - here you can create new notebooks, or open existing ones. Our homework assignments will always be based on a  template notebook , available in this GitHub repository. To start from a template notebook on the web, you can  paste the URL into the blue box  and press ENTER. For example, homework 0 is available  here . Go to this page, and on the top right, click on the button that says “Edit or run this notebook”. From these instructions, copy the notebook link, and paste it into the box. Press ENTER, and select OK in the confirmation box. The first thing we will want to do is to save the notebook somewhere on our own computer; see below. Step 2b: Opening an existing notebook file When you launch Pluto for the second time, your recent notebooks will appear in the main menu. You can click on them to continue where you left off. If you want to run a local notebook file that you have not opened before, then you need to enter its  full path  into the blue box in the main menu. More on finding full paths in step 3. Step 3: Saving a notebook We first need a folder to save our homework in. Open your file explorer and create one. Next, we need to know the  absolute path  of that folder. Here’s how you do that in  Windows ,  MacOS  and  Ubuntu . For example, you might have: C:\\Users\\fons\\Documents\\18S191_assignments\\  on Windows /Users/fons/Documents/18S191_assignments/  on MacOS /home/fons/Documents/18S191_assignments/  on Ubuntu Now that we know the absolute path, go back to your Pluto notebook, and at the top of the page, click on  “Save notebook…” . This is where you type the  new path+filename for your notebook : Click  Choose . Step 4: Sharing a notebook After working on your notebook (your code is autosaved when you run it), you will find your notebook file in the folder we created in step 3. This the file that you can share with others, or submit as your homework assignment to Canvas. \nconst run = f => f();\nrun(async () => {\nconst versions = await (await fetch(`https://julialang-s3.julialang.org/bin/versions.json`)).json()\nconst version_names = Object.keys(versions).sort().reverse()\nconst stable = version_names.find(v => versions[v].stable)\nconsole.log({stable})\nconst pkg_stable = /\\d+\\.\\d+/.exec(stable)[0]\ndocument.querySelectorAll(\"auto-julia-version\").forEach(el => {\n    console.log(el)\n    el.innerText = el.getAttribute(\"short\") == null ? stable : pkg_stable\n})\n});"},{"url":"introduction/","title":"Introduction","tags":["welcome"],"text":"main a img {\n    width: 5rem;\n    margin: 1rem;\n}\n Earth, in all its grand complexity, whispers its secrets through an orchestra of data. In this course, we’ll become skilled detectives, equipped with powerful analytical tools to decode these whispers and unlock the mysteries of our planet. Let’s imagine Earth as a puzzle box, with three chambers holding the keys to understanding its dynamic processes. The first chamber houses the measured quantities, fingerprints of its current state. The second holds the governing laws, the hidden rules that orchestrate its dance. And finally, in the third chamber lie the hidden parameters, unseen yet crucial players in this grand story. This course equips you with the skills to tackle various challenges, depending on what’s known and what needs to be revealed. We’ll dive into: Inverse Problems : When the rules are known but the players hiding in the shadows remain unseen. Like a detective reconstructing a crime scene, we’ll use data and laws to unmask these hidden parameters. Learning Problems : When the rules themselves are shrouded in mystery. We’ll become data-driven alchemists, transforming information into a map of the underlying laws that govern Earth’s behavior. Design Problems : Before the experiment even begins, we’ll become master strategists, designing data acquisition to optimally reveal the hidden secrets we seek. Throughout this journey, we’ll explore a diverse range of Earth science applications, from predicting climate change to understanding earthquakes. You’ll not only gain technical skills in data analysis but also forge a deeper connection with our planet, appreciating its interconnectedness and learning to ask the right questions to unlock its secrets."},{"url":"linear-algebra/","title":"Linear Algebra Primer","tags":["welcome"],"text":" A Pluto.jl notebook v0.19.36 frontmatter order \"2\" title \"Linear Algebra Primer\" date \"2024 01 04\" tags \"welcome\" description \"Refresh your concepts of linear algebra. Thank you Gilbert Strang.\" layout \"layout.jlhtml\" using Markdown using InteractiveUtils This Pluto notebook uses bind for interactivity. When running this notebook outside of Pluto, the following 'mock version' of bind gives bound variables a default value instead of an error . macro bind def, element quote local iv try Base.loaded modules Base.PkgId Base.UUID \"6e696c72 6542 2067 7265 42206c756150\" , \"AbstractPlutoDingetjes\" .Bonds.initial value catch b missing end local el esc element global esc def Core.applicable Base.get, el ? Base.get el iv el el end end begin using LinearAlgebra using PlutoUI using PlutoTeachingTools using Symbolics using PlutoPlotly end ChooseDisplayMode TableOfContents md\"\"\" Linear Algebra Primer It is one of the mathematical pillars of our course the measured data is often organized to form a vector d in many problems, the physics is often simplified linearized to form a matrix G that maps the model vector m to produce measurements d ```math d G m. ``` In this notebook, we shall try to revisit some highlights of linear algebra. Hopefully, as most of you learned these basic concepts, this notebook will serve as a necessary primer One needs to develop a good geometrical picture of the concepts. For example, we would like to clearly visualize the least squares solution ```math \\hat m G^TG ^ 1 G^T d ``` that you will encounter soon. \"\"\" md\"\"\" Vectors \"\"\" data 0.4, 2.4, 5.6, 9 typeof data danger md\"`x 1,2,3 ` will result in a simple list called `Tuple` in Julia, it is different from a `Vector Float64 ` \" typeof 0.4, 2.4, 5.6, 9 md\"It is easy to check the length of arrays.\" length data md\"\"\" Scalar vector multiplication \"\"\" 3.0 data md\"\"\" Indexing \"\"\" data 1 2 data end first data last data md\"\"\" Concatenate \"\"\" data2 1.2, 3.4, 4.5 data full vcat data, data2 cat data, data2, dims 1 data3 1, 2, 3 vcat data, data3 aaa Float32. data full typeof aaa md\"\"\" Special arrays \"\"\" typeof zeros 5 typeof zeros Float32, 5 randn Float32, 10 md\"\"\" Linear combination Two arrays of same size can be added together. \"\"\" 0.5 . randn 5 . 0.3 randn 5 md\"\"\" Inner product \"\"\" v1 2.0, 3.4, 4.5 v2 1.0, 3.4, 4.5 dot v1, v2 sum v1 . v2 alternatively md\" Matrix vector multiplication\" syms m₁ m₂ m m₁, m₂ g₁ 0.2, 0.1, 3 g₂ 1, 0.2, 0.1 G hcat g₁, g₂ simply a collection of vectors columns d G m Markdown.MD Markdown.Admonition \"warning\", \"Intuition\", md\"\"\" The multiplication of G times m can be interpreted in two ways 1 linear combination of columns g 1 and g 2 which means the vector G\\,m belongs to the column space of G 2 an inner product between each row of G with the vector m roughly, what is the correlation of each row of G with the vector m ? \"\"\" linear combination of columns m₁ G , 1 m₂ G , 2 aside Markdown.MD Markdown.Admonition \"therom\", \"Think\", md\"\"\" Is there any linear combination, other than m 1 0 and m 2 0 , of g 1 and g 2 that produces a zero vector? Why not? \"\"\" md\"\"\" This means G\\,m lies in the space of g 1 and g 2 . You can get convinced by using the sliders below. Choose m₁ bind x₁p Slider range 1, 1, length 10 , default 0.5, show value true m₂ bind x₂p Slider range 1, 1, length 10 , default 0.5, show value true \"\"\" alternatively, inner product with rows sum G 1, . m , sum G 2, . m , sum G 3, . m md\"\"\" Outer product Results in a matrix with dependent columns on u ```math A u\\,v^ T . ``` \"\"\" bind resample1 Button \"Resample\" begin resample1 A1 randn 3 transpose randn 4 end md\"\"\" Rank building blocks of a matrix The rank of a matrix is the dimension of its column space. Let's check the rank of the matrix that we created using the outer product. We know that it has only one independent column. \"\"\" rank A1 md\"Now, lets add two rank 1 peices together.\" A2 randn 3 randn 4 ' . randn 3 randn 4 ' rank A2 md\"Obviously, a matrix with 3 rows has full rank if we add at least 3 rank 1 outer products together. To show this, we will create a matrix using `for` loop in Julia.\" rank sum randn 3 randn 7 ' for in 1 10 md\"\"\" Conversely, any matrix can be decomposed into rank 1 pieces We will talk more about this when working with singular value decomposition SVD . \"\"\" md\"\"\" Matrix matrix multiplication Product of two matrices C and R ```math CR \\text columns of C \\text times rows of R. ``` There are many ways of factoring A . Even though A is a fat matrix, we can simply collect the basis for the column space of A to form C . Other left out dependent columns can be generated later using R to form first great theorem ```math A C\\,R. ``` Two views again 1 linear combination of columns of C using each column of R earlier, we discussed this when R has only one column, i.e., it is a vector 2 or linear combination of rows of R using rows of C . Finally, we can show that the number of independent columns of C equals the number of rows of R . \"\"\" md\"\"\" Singular value decomposition \"\"\" md\"\"\" You are now given a fat matrix X , with a bunch of columns, much more than 3 column size . Obviously, there are only 3 independent columns in X. What are they? Can we order them by importance? \"\"\" bind resample2 Button \"Resample\" begin resample2 X randn 3, 3 randn 3, 20 create a fat matrix end md\"\"\" Choose the number of singular vectors for plotting bind ns Slider 1 3, show value true, default 1 \"\"\" sX svd X md\"Let's only pick the first rank 1 piece\" norm X . sX.U , 1 sX.V , 1 ' . sX.S 1 md\"If we pick the second piece, then the distance is higher.\" norm X . sX.U , 2 sX.V , 2 ' . sX.S 2 md\"and so on\" norm X . sX.U , 3 sX.V , 3 ' . sX.S 3 Markdown.MD Markdown.Admonition \"note\", \"Eckart Young Theorem\", md\"\"\" The Frobenius Norm of X is equal to the sum of squares of singular values. ```math ||X||^2 \\sigma 1^2 \\sigma 2^2 \\sigma 3^2 \\cdots ``` \"\"\" md\"Let's test this out...\" norm X ^2 Frobenius norm sum sX.S .^ 2 sum of squared singular values md\"Finally, we understand how to arrange singular vectors by importance, at least in the L2 sense.\" md\"\"\" Nullspace Now we are interested in a linear combination of the columns of a matrix that generates a zero vector. Other than the trivial case of multiplying all the columns with zero, when is such a non zero combination possible? Obviously, we cannot combine independent vectors to produce zero. \"\"\" Markdown.MD Markdown.Admonition \"note\", \"Counting Law\", md\"\"\" A matrix G has rank r then the equation G\\,m 0 has n r independent solutions, where n is the number of columns of G . \"\"\" md\"\"\" Appendix \"\"\" md\" Plots\" function myquiver v, names fill \"\", length v , colors fill \"black\", length v , title \"\" layout Layout title title, scene attr uirevision 1, aspectmode \"manual\", aspectratio attr x 1, y 1, z 1 , xaxis attr nticks 4, range 5, 5 , yaxis attr nticks 4, range 5, 5 , zaxis attr nticks 4, range 5, 5 , , p scatter x 0, vv 1 , y 0, vv 2 , z 0, vv 3 , mode \"markers lines\", marker attr size 2, symbol \"\", \"x\" , color color, set color to an array list of desired values opacity 0.8 , name name, type \"scatter3d\" for name, color, vv in zip names, colors, v return plot p, layout end myquiver g₁, g₂, G x₁p, x₂p , \"g₁\", \"g₂\", \"G m\" , \"black\", \"black\", \"red\" , \"Column space of G\" myquiver A1 , 1 , A1 , 2 , A1 , 3 , A1 , 4 , \"a₁\", \"a₂\", \"a₃\", \"a₄\" , fill \"black\", 4 , \"Columns of outerproduct u, v \" myquiver vcat X , i for i in 1 size X, 2 , sX.U , i . sX.S i for i in 1 ns , fill nothing, 20 ns , vcat fill \"black\", 20 , fill nothing, ns , \" ns Orthonormal Singular Vector s \" md\"\"\" Resources ^Book Linear algebra and learning from data, Gilbert Strang ^Youtube Essence of linear algebra https www.youtube.com playlist?list PLZHQObOWTQDPD3MizzM2xVFitgF8hE ab , 3Blue1Brown \"\"\" "},{"url":"logistics/","title":"Course Logistics","tags":["welcome"],"text":"main a img {\n    width: 5rem;\n    margin: 1rem;\n}\n Grading Describe here the logistics of your class."},{"url":"references/","title":"References","tags":["welcome"],"text":"main a img {\n    width: 5rem;\n    margin: 1rem;\n}\n Books Menke, William. Geophysical data analysis: Discrete inverse theory. Academic press, 2018. Tarantola, Albert. Inverse problem theory and methods for model parameter estimation. Society for industrial and applied mathematics, 2005. Robinson, Enders A., and Sven Treitel. Geophysical signal analysis. Society of Exploration Geophysicists, 2000 A. Blum, J. Hopcroft, and R. Kannan (2020) Foundations of Data Sciences, Cambridge University Press James, G., Witten, D., Hastie, T., & Tibshirani, R. (2013). An introduction to statistical learning (Vol. 112, p. 18). New York: Springer. Boyd, Stephen, and Lieven Vandenberghe. Introduction to applied linear algebra: vectors, matrices, and least squares. Cambridge university press, 2018. Video Lectures Essence of linear algebra , 3Blue1Brown"},{"url":"search/","title":"Search results","tags":[],"text":"window.init_search(); Search Results \nLoading..."},{"url":"assets/scripts/get_highlights/","title":"get_highlights","tags":[],"text":"if isempty get metadata \"homepage\" , \"highlights\", nothing else highlights htl \"\"\" section div class \"content\" h2 x \"name\" h2 p x \"text\" p div div class \"preview\" img src \" x \"img\" \" div section \"\"\" for x in metadata \"homepage\" \"highlights\" htl \"\"\" div class \"subjectscontainer wide\" h1 Highlights h1 div class \"contain\" highlights div div \"\"\" end"},{"url":"assets/scripts/get_subjects/","title":"get_subjects","tags":[],"text":"let sections metadata \"sidebar\" sections htl \"\"\" let input other page.input output other page.output name get output.frontmatter, \"title\", basename input.relative path desc get output.frontmatter, \"description\", nothing tags get output.frontmatter, \"tags\", String image get output.frontmatter, \"image\", nothing class \"no decoration\", \"tag replace x, \" \" \" \" \" for x in tags ..., image nothing || isempty image ? nothing htl \"\"\" a title desc class class href root url \" \" other page.url h3 name h3 img src image a \"\"\" end for other page in collections section id .pages \"\"\" for section id, section name in sections isempty sections ? nothing htl \"\"\" div class \"wide subjectscontainer\" h1 Subjects h1 div class \"subjects\" sections div div \"\"\" end"},{"url":"mod1_inverse_theory/least-squares-line-fitting/","title":"Least Squares Line Fitting","tags":["module1"],"text":" A Pluto.jl notebook v0.19.36 frontmatter chapter \"1\" title \"Least Squares Line Fitting\" tags \"module1\" layout \"layout.jlhtml\" using Markdown using InteractiveUtils This Pluto notebook uses bind for interactivity. When running this notebook outside of Pluto, the following 'mock version' of bind gives bound variables a default value instead of an error . macro bind def, element quote local iv try Base.loaded modules Base.PkgId Base.UUID \"6e696c72 6542 2067 7265 42206c756150\" , \"AbstractPlutoDingetjes\" .Bonds.initial value catch b missing end local el esc element global esc def Core.applicable Base.get, el ? Base.get el iv el el end end using LinearAlgebra, PlutoUI, PlutoTeachingTools, Symbolics, Distributions, PlutoPlotly TableOfContents md\" Fitting A Straight Line\" md\"We will consider a simple inverse problem here Suppose that N temperature measurements Ti are made at times ti in the atmosphere. We assume that the temperature is a simple linear function of time. There are two model parameters in this problem, the slope of the straight line and its y intercept. \" md\"\"\" Configuration bind config MultiCheckBox \"Additive Gaussian Noise\", \"Outlier\", \"Constraint\" , default \"Additive Gaussian\", \"Constraint\" \"\"\" md\"\"\" Click to regenerate 1 bind renoise Button \"Noise\" 2 bind reout Button \"Outlier\" 3 bind recon Button \"Constraint\" \"\"\" Markdown.MD Markdown.Admonition \"warning\", \"Intuition\", md\"\"\" Regenerate noise to notice that the variance along the y intercept dimension is higher than the variance along the slope dimension. This means the estimate of the slope is less uncertain than the y intercept. Notice the broad minimum along the y intercept dimension compared to the sharp minimum along the slope dimension. \"\"\" md\"\"\" Line Fitting \"\"\" begin sloper range 2, stop 5, length 100 range for slope yintr range 2, stop 5, length 100 range for y intercept end begin choose the number of data points and control variable x N 10 change this to K x range 1, stop N end forward map G hcat x, ones N G' G choose true model parameters mtrue 3.0, 0.4 md\"\"\" Least squares functional has the form ```math J G\\cdot m d ^\\top \\cdot G\\cdot m d ``` which can be written as ```math J m^\\top G^\\top G\\,m\\, \\,2\\,m^\\top\\,G^\\top\\,d\\, d^\\top\\,d ``` gradient w.r.t. m ```math \\frac \\partial J \\partial m 2\\cdot G^\\top \\cdot G\\cdot m d ``` solution using the Moore Penrose inverse ```math G^TG ^ 1 G^Td ``` \"\"\" md\"\"\" Notice that the columns of G are linearly independent, therefore G^\\top G is invertible. \"\"\" G⁻ᵍ inv transpose G G transpose G y nonoise G mtrue m slope, yintercept md\"\"\" Error Bowl \"\"\" Markdown.MD Markdown.Admonition \"formula\", \"Gradient and Hessian of Linear and Quadratic Functions\", md\"\"\" A linear function of the form ```math f m a^\\top\\,m ``` had gradient \\nabla\\,f a . The quadratic function of the form ```math f m m^\\top\\,A\\,m ``` has gradient \\nabla\\,f A A^\\top \\,m and Hessian \\nabla^2\\,f A A^\\top . These results can be derived by utilizing summation notation, taking partial derivatives, and subsequently recombining these partial derivatives into matrix form. \"\"\" plot heatmap x \"1\", \"2\" ,y \"1\",\"2\" , z G' G , Layout title \"Hessian Matrix\", width 550 md\"\"\" Lagrangian The Lagrangian is a function of m\\in\\mathbb R ^N and \\lambda\\in\\mathbb R ^P , i.e., N P variables. We produce N equations when differentiating w.r.t. each element of m and P equations when differentiating w.r.t. each element of \\lambda . \"\"\" generate observed data and add noise begin renoise y randnoise copy y nonoise some random noise to the data if \"Additive Gaussian Noise\" ∈ config y randnoise . randn N 0.5 end end begin reout y copy y randnoise add an outlier if \"Outlier\" ∈ config y rand 1 N 2.0 end end mest G⁻ᵍ y Jbowl broadcast Iterators.product sloper, yintr do m1, m2 sum abs2. G m1, m2 . y end begin recon x1 rand Uniform 1, 4 y1 rand Uniform extrema y ... end H x1, 1 ' md\"\"\" Constrained Problem Number of constraints P ```math Hm h 0 ``` \"\"\" h y1 md\"\"\" ```math \\begin bmatrix G^TG & H^T \\\\ H & 0 \\end bmatrix \\begin bmatrix m \\\\ \\lambda \\end bmatrix \\begin bmatrix G^Td \\\\ h \\end bmatrix ``` \"\"\" md\"\"\" Lagrangian ```math \\mathbb L G\\cdot m d ^\\top \\cdot G\\cdot m d λ^\\top \\cdot H\\cdot m h ``` gradient w.r.t. m ```math \\frac \\partial \\mathbb L \\partial m 2\\cdot G^\\top \\cdot G\\cdot m d H^\\top \\cdot \\lambda ``` gradient w.r.t. \\lambda ```math \\frac \\partial \\mathbb L \\partial \\lambda H\\cdot m h ``` \"\"\" yc G' y y1 Gc G' G H' H 0 mestc inv transpose Gc Gc transpose Gc yc mestc md\" Data Resolution Matrix\" Rd G G⁻ᵍ plot heatmap x string. 1 size Rd,1 ,y string. 1 size Rd,1 ,z Rd ,Layout title \"Data Resolution Matrix\", width 550 md\"\"\" The diagonal elements of Data resolution matrix indicate how much weight a datum has in its own prediction. The diagonal elements are often singled out and called importance of the data. In this case, \"\"\" plot scatter x x, y diag Rd , Layout title \"Data Importance\", xlabel \"x\" md\"\"\" Curvature for the prediction error given by the second derivative \"\"\" md\" Model Resolution Matrix\" Rm G⁻ᵍ G plot heatmap x \"1\",\"2\" , y \"1\",\"2\" ,z Rm , Layout title \"Model Resolution Matrix\", width 550 md\" Appendix\" md\" Global Temperature Data Hansen, J., R. Ruedy, Mki. Sato, and K. Lo, 2010 Global surface temperature change. Rev. Geophys., 48, RG4004, doi 10.1029 2010RG000345\" global temp data 1965 0.11 1966 0.03 1967 0.01 1968 0.04 1969 0.08 1970 0.03 1971 0.10 1972 0.00 1973 0.14 1974 0.08 1975 0.05 1976 0.16 1977 0.12 1978 0.01 1979 0.08 1980 0.19 1981 0.26 1982 0.04 1983 0.25 1984 0.09 1985 0.04 1986 0.12 1987 0.27 1988 0.31 1989 0.19 1990 0.36 1991 0.35 1992 0.13 1993 0.13 1994 0.23 1995 0.37 1996 0.29 1997 0.39 1998 0.56 1999 0.32 2000 0.33 2001 0.47 2002 0.56 2003 0.55 2004 0.48 2005 0.62 2006 0.55 2007 0.58 2008 0.44 2009 0.58 2010 0.63 plot scatter x global temp data , 1 , y global temp data ,2 , name \"a\" , , Layout xaxis attr title \"Year\" , yaxis attr title \"Temperature Anomaly °C \" md\"\"\" References Useful resources for matrix calculus https www.matrixcalculus.org https www.matrixcalculus.org http www.ee.ic.ac.uk hp staff dmb matrix intro.html http www.ee.ic.ac.uk hp staff dmb matrix intro.html \"\"\" md\" Plots\" pbowl let s contour x yintr, y sloper, z Jbowl, colorscale \"Hot\", colorbar attr thickness 25, thicknessmode \"pixels\", len 0.3, lenmode \"fraction\", outlinewidth 0 , scatter x mtrue 2 , y mtrue 1 , mode \"markers\",name \"True Model\", marker attr color green , scatter x mest 2 , y mest 1 , mode \"markers\", name \"Estimated Model\", marker attr color blue if \"Constraint\" ∈ config push s, scatter x mestc 2 , y mestc 1 , mode \"markers\", name \"Constrained Model\", marker attr color red push s, scatter x y1 . sloper . x1, y yintr, mode \"lines\", name \"Constraint\", marker attr color red end plot s, Layout xaxis attr title \"Intercept\" , yaxis attr title \"Slope\" end pline let s scatter x x, y y, mode \"markers\", name \"Observations\", marker attr color black , scatter x x, y G mest, mode \"lines\", name \"Estimated Model\", line attr color blue , scatter x x, y G mtrue, mode \"lines\", name \"True Model\", line attr color green if \"Constraint\" ∈ config push s, scatter x x1 , y y1 , mode \"markers\", name \"Constraint\", marker attr color red push s, scatter x x, y G mestc 1 2 , mode \"lines\", name \"Constrained Model\", line attr color red end plot s, Layout xaxis attr title \"Year\" , yaxis attr title \"Temperature Anomaly °C \" end PlutoUI.ExperimentalLayout.vbox pline, pbowl "},{"url":"mod1_inverse_theory/monte-carlo-sampling/","title":"Monte Carlo Methods","tags":[],"text":" A Pluto.jl notebook v0.19.36 frontmatter chapter \"1\" title \"Monte Carlo Methods\" layout \"layout.jlhtml\" description \"How can we balance the trade off between taking large steps with many rejections versus taking small steps with few rejections?\" using Markdown using InteractiveUtils This Pluto notebook uses bind for interactivity. When running this notebook outside of Pluto, the following 'mock version' of bind gives bound variables a default value instead of an error . macro bind def, element quote local iv try Base.loaded modules Base.PkgId Base.UUID \"6e696c72 6542 2067 7265 42206c756150\" , \"AbstractPlutoDingetjes\" .Bonds.initial value catch b missing end local el esc element global esc def Core.applicable Base.get, el ? Base.get el iv el el end end begin using Distributions, Plots, PlutoUI, PlutoTeachingTools using StatsPlots, MLUtils, Interpolations, Measures, ImageFiltering end TableOfContents ChooseDisplayMode md\" Monte Carlo Sampling\" bind sample true density Button \"Change True Density Model\" md\"\"\" Prior Movie bind sample prior density Button \"Sample Prior Density Models\" Smooth? bind smooth prior flag CheckBox default false \"\"\" md\"\"\" Posterior Movie bind sample posterior density Button \"Sample Posterior Density Models\" Smooth? bind smooth posterior flag CheckBox default false \"\"\" md\" Simpler Demo\" md\" Striking the balance\" Markdown.MD Markdown.Admonition \"wrg\", \" Large Steps & Many Rejects Vs. Small Steps & Few Rejects \", md\"\"\" The acceptance ex1 rate of the Metropolis criterion has to be around 30 50\\% . If the acceptance ex1 rate is, we are not moving fast enough in the model space. On the other hand, if the acceptance ex1 rate is much smaller, then we are wasting computer resources as most of the samples are not accepted. \"\"\" md\" Metropolis Criterion\" Markdown.MD Markdown.Admonition \"info\", \"Metropolis Criterion\", md\"\"\" Consider some random rules that define a random walk. This random walk, if unmodified, samples some initial probability distribution. The metropolis algorithm modifies the random walk, by accepting or rejecting a proposed transition m i\\to m j using the following rules if L m j ≥ L m i , then accept the proposed transition else if L m j L m i , then decide randomly whether to accept or reject, with the following probability of accepting the move to m j ```math P i\\to j \\frac L m j L m i . ``` It can be shown that the random walker samples the conjunction of the probability densities \\rho m and L m , given by ^1 ```math σ m \\rho m \\wedge\\,L m \\mathrm const . \\rho m L m ``` ^1 We have assumed the homogeneous distribution \\mu m to be a constant for simplicity. \"\"\" md\"\"\" This function takes three mandatory inputs `m0` which is the initial model, prior which is a function that samples from the prior distribution, and `L` which is a function that evaluates the likelihood of a model. The function also takes an optional input `N` which is the number of samples to generate and is set to 100 by default. The function generates samples using the Metropolis Hastings algorithm, which is a Markov Chain Monte Carlo MCMC method. It initializes the first sample to `m0`, and then repeatedly generates a new candidate sample using the prior function. It then evaluates the likelihood of the candidate sample using the `L` function and computes the Metropolis Hastings ratio. If the ratio is greater than a randomly generated number from a Bernoulli distribution, the candidate sample is accepted as the next sample, and the process is repeated until N samples are generated or the loop breaks. The function returns two objects `msamples ex1`, which is an array of the generated samples, and `acceptance ex1 history`, which is an array that keeps track of whether a sample was accepted or rejected at each step of the Metropolis Hastings algorithm. \"\"\" function generate samples m0, walk, L N 10 msamples ex1 push msamples ex1, m0 acceptance ex1 history metropolis ratios create an array to store previous model mp copy m0 evaluate the initial likelihood p current L nothing ? 1.0 L m0 i 0 while i ≤ N sample from prior to get destination m walk mp evaluate prob of destination p prop L nothing ? 1.0 L m metropolis ratio metropolis ratio p prop p current push metropolis ratios, metropolis ratio if rand Bernoulli min 1, metropolis ratio mp copy m p current p prop push msamples ex1, m push acceptance ex1 history, true i 1 else simply revert back push acceptance ex1 history, false end end return msamples ex1, acceptance ex1 history end md\" Simple 2D Example\" method to generate 2 D example target probability density function Lex1 m s1 1.0 s2 0.5 return exp 0.5 m 1 1.7 ^2 m 2 ^2 s1^2 2.0 pi s2 exp 0.5 m 1 2.0 ^2 m 2 ^2 s2^2 2.0 pi s2 end md\"\"\" Use Metropolis criterion? bind metro Select Lex1 \"Yes\", nothing \"No\" \"\"\" range ex1 range 10, stop 10, length 256 Lex1 grid Lex1 x, y for x in range ex1, y in range ex1 md\"\"\" This function generates a 2D random walk step by drawing two independent random numbers from a normal distribution with mean 0 and standard deviation 1, scaling them by a factor of 10, and returning them as a 2D vector. The resulting step is uncorrelated with any previous steps and is independent of the current position. This is an example of an independent random walk. \"\"\" md\"\"\" This function generates a proposal for a 2D random walk by adding random perturbations to the current model m based on a Gaussian distribution with standard deviation sigma of 1.0. This is a local proposal, where each step is a small perturbation around the current point. \"\"\" heatmap range ex1, range ex1, Lex1 grid, c grays, title \"Likelihood Distribution\", aspect ratio 1 md\" Gravity Example ^mosegaard1995 \" md\"\"\" Note that the complex prior knowledge used in this example renders the posterior distribution to be non Gaussian. \"\"\" xrange ex2 range 1, stop 40, length 20 ρrange 100, 6000 md\" Samplers\" md\"\"\" This sampler output neighbors of an input model by creating or destroying a new interface in the model. \"\"\" md\"\"\" Physics We measure the horizontal derivative of the vertical component of the acceleration due to gravity. Contribution from a homogeneous half layer is given by ```math G\\Delta\\rho\\,\\log\\left \\frac z 2^2 x^2 z 1^2 x^2 \\right , ``` where depth of the top pf the layer is z 1 the depth of the bottom is z 2 horizontal density contrast is \\Delta\\rho . \"\"\" function ggravity m, xrange xrange ex2 Gconst 6.6743 1e 11 m3 kg 1 s 2 ρ left half 2570 kg m3 l, ρ splitobs m, at 0.5 l l . 1e3 return broadcast xrange do x xm x 1e3 km to m data 0.0 d 0 first layer at zero depth for i in 1 length l data Gconst ρ i ρ left half log abs2 d l i abs2 xm inv abs2 d abs2 xm d l i depth of top of next layer end return data end end md\" Prior\" pρ Gumbel 3000, 400 plot pρ, w 2, label nothing, title \"Prior Mass Density Distribution\", c black, size 500, 250 pl Exponential 4 function randomwalk density independent m, pl pl, pρ pρ l Vector Float64 undef, 0 d 0 cumulative sum of widths while d 100 less than 100 km l1 rand pl push l, l1 d l1 end change last layer to obey 100 km constraint l end 100 sum l 1 end 1 pick density values ρ rand pρ, length l model vector is vcat of l and d return cat l, ρ, dims 1 end begin sample true density mex2 true randomwalk density independent 0 end dobs ex2 ggravity mex2 true, xrange ex2 msamples ex2 prior randomwalk density independent 0 for i in 1 100 function randomwalk density dependent m, pl pl, pρ pρ mout copy m l, ρ splitobs mout, at 0.5 nlayers length l if rand Bernoulli 0.5 change density of randomly chosen layer k randobs 1 nlayers ρ k rand pρ else for wait in 1 5 ib randobs 2 nlayers L l ib l ib 1 l ib rand truncated pl, 0, L l ib 1 L l ib ρ ib rand pρ ρ ib 1 rand pρ end end return cat l, ρ, dims 1 end plot pl, w 2, label nothing, title \"Prior Layer Thickness Distribution\", c black, size 500, 250 md\" Likelihood\" md\"\"\" References ^mosegaard1995 Monte Carlo sampling of solutions to inverse problems, Mosegaard and Tarantola, JGR, 1995. \"\"\" md\" Appendix\" md\" UI\" function sampler input ex2 return PlutoUI.combine do Child p md\"\"\" Initial model m₁ Child \"m₁0\", Slider range ex1, default 5, show value true and m₂ Child \"m₂0\", Slider range ex1, default 5, show value true \"\"\", σ md\"\"\" Standard deviation for prior distribution for drawing independent samples Child \"σglobal\", Slider range 0.05, stop 10, length 100 , default 10, show value true Standard deviation for local proposal Child \"σlocal\", Slider range 0.001, stop 10, length 10 , default 1, show value true \"\"\", md\"\"\" Design the random walk p σ \"\"\" end end function sampler input ex1 return PlutoUI.combine do Child p md\"\"\" Initial model m₁ Child \"m₁0\", Slider range ex1, default 5, show value true and m₂ Child \"m₂0\", Slider range ex1, default 5, show value true \"\"\", σ md\"\"\" Standard deviation for prior distribution for drawing independent samples Child \"σglobal\", Slider range 0.05, stop 10, length 100 , default 10, show value true Standard deviation for local proposal Child \"σlocal\", Slider range 0.001, stop 10, length 10 , default 1, show value true \"\"\", md\"\"\" Design the random walk p σ \"\"\" end end bind ex1 confirm sampler input ex1 function randomwalk ex1 independent m sigma ex1 σglobal return sigma . randn 2 . 0.5 end function randomwalk ex1 local m sigma ex1 σlocal return m . sigma . randn 2 end md\"\"\" Generate bind Nex1 Slider 1 256, default 20, show value true samples which are bind walk Select randomwalk ex1 independent \"Independent\", randomwalk ex1 local \"Markov Chain\" \"\"\" msamples ex1, acceptance ex1 generate samples ex1 m₁0 , ex1 m₂0 , walk, metro, N Nex1 begin p1 heatmap range ex1, range ex1, Lex1 grid, c grays, lim 10, 10 , xlabel \"m₁\", aspect ratio 1, ylabel \"m₂\", title \"Accepted Nex1 length acceptance ex1 with ratio round count acceptance ex1 length acceptance ex1 , digits 3 \" scatter p1, msamples ex1 1 1 1 , msamples ex1 1 2 2 , c yellow, m x, label \"Initial Sample\" gif for isamp in 2 length msamples ex1 println m, acc plot p1, msamples ex1 isamp 1 2 , msamples ex1 isamp 2 , msamples ex1 isamp 1 1 , msamples ex1 isamp 1 , c blue, label nothing end end md\" Plots\" begin userplot pdensity model recipe function f h pdensity model smooth false grid true size 200, 300 margin 1cm color black seriestype steppre colorbar nothing yflip true xlim 100, 6000 ylim 0, 100 w 2 xlabel \"Density kg m3 \" ylabel \"Depth km \" xticks 1000, 5000 titlefontsize 10 guidefontsize 7 tickfontsize 7 label nothing series begin l, ρ splitobs h.args 1 , at 0.5 l1 vcat 0.0 , cumsum l ρ1 vcat ρ, ρ end end if h.args 2 itp interpolate l1, , ρ1, Gridded Linear zrange range 0.1, stop 99.9, length 256 ρ2, l2 vec imfilter cat itp. zrange , dims 2 , Kernel.gaussian 3 , zrange else ρ2, l2 ρ1, l1 end ρ2, l2 end end end plot pdensity model msamples ex2 prior 1 , false, title \"Initial Sample\" , pdensity model randomwalk density dependent msamples ex2 prior 1 , false, title \"Perturbed Sample\" , size 500, 300 function plot true density model plot pdensity model mex2 true, false, title \"True Earth Model\" , pdensity model mex2 true, true, title \"Smoothed True Model\" , size 450, 300 , margin 5mm end TwoColumnWideRight md\"\"\" Gravity Inversion PlutoUI.LocalResource \"gravity inversion example.png\", width 300 Standard deviation of normally distributed gravity measurements bind σex2 Slider range 0.1e 8, stop 3e 8, length 10 , default 0.1e 6, show value true \"\"\", md\" plot true density model \" pd ex2 MvNormal dobs ex2, σex2 function Lex2 m, pd pd ex2, xrange xrange ex2 d ggravity m, xrange return pdf pd ex2, d end msamples ex2, acceptance ex2 generate samples randomwalk density independent 0 , randomwalk density dependent, Lex2, N 100 count acceptance ex2 length acceptance ex2 function plot density model m p1 plot playered model m, false p2 plot playered model m, true plot p1, p2, size 400, 300 , margin 1cm end function pdensity models mvec, smooth plot pdensity model m, smooth, xlabel \"\", ylabel \"\", margin 1mm, left margin 2.0 Plots.mm, right margin 2.0 Plots.mm, showaxis false, axis nothing for m in mvec ..., layout 1, length mvec , size 650, 300 , axis nothing end begin sample prior density pdensity models randomwalk density independent 0 for i in 1 6 , smooth prior flag end begin sample posterior density pdensity models randobs msamples ex2 end 20 end , 6 , smooth posterior flag end pdata ex2 plot xrange ex2, dobs ex2, w 2, size 500, 250 , xlim extrema xrange ex2 , label \"Observed Data\", xlabel \"sensor horizontal position\", ylabel \"\", titlefontsize 10, guidefontsize 7, tickfontsize 7, function plot prior data ex2 pdata ex2 prior deepcopy pdata ex2 for i in 1 20 plot pdata ex2 prior, xrange ex2, ggravity randomwalk density independent 0 , xrange ex2 , w 2, c black, alpha 0.3, label nothing, title \"Prior\" end pdata ex2 prior end function plot post data ex2 pdata ex2 post deepcopy pdata ex2 for m in msamples ex2 end 20 end plot pdata ex2 post, xrange ex2, ggravity m, xrange ex2 , w 2, c black, alpha 0.3, label nothing, title \"Posterior\" end pdata ex2 post end md\"\"\" Data Movie plot plot prior data ex2 , plot post data ex2 , size 650, 250 , link y \"\"\" "},{"url":"mod1_inverse_theory/probabilistic-inverse-problems/","title":"Probabilistic Inverse Problems","tags":[],"text":" A Pluto.jl notebook v0.19.25 frontmatter chapter 1 section 4 order 4 layout \"layout.jlhtml\" title \"Probabilistic Inverse Problems\" description \"Posterior Information Conjunction Prior Information, Theoretical Information .\" using Markdown using InteractiveUtils This Pluto notebook uses bind for interactivity. When running this notebook outside of Pluto, the following 'mock version' of bind gives bound variables a default value instead of an error . macro bind def, element quote local iv try Base.loaded modules Base.PkgId Base.UUID \"6e696c72 6542 2067 7265 42206c756150\" , \"AbstractPlutoDingetjes\" .Bonds.initial value catch b missing end local el esc element global esc def Core.applicable Base.get, el ? Base.get el iv el el end end ChooseDisplayMode TableOfContents md\"\"\" Probabilistic Inverse Problems The fundamental idea of probabilistic inverse theory is to express all knowledge concerning model parameters, data, and the physical theory in terms of probabilities. Frequentist interpretation of probability is simple it considers a large number of repeatable experiments. When we don't consider repeatable experiments, we adopt the Bayesian interpretation of probabilities, where they represent state of information. \"\"\" bind sex source loc ex input plot ρ plot, Θ plot, σ plot, layout 1, 3 , size 1000, 350 , margin 4mm plot sxgrid, sum ρex . Θex, dims 2 , w 2, c black, title \"Marginalized Posterior Model Information\", xlabel \"Source x location\", size 500, 250 , label nothing md\"\"\" Repeating Experiments The data measured at the receivers are no longer certain. They change from one experiment to another. For example, we can measure the traveltime at a specific receiver 10 times after repeating the experiment. \"\"\" scatter rand pdata1, 10 , ylim 0.5, 1.5 , xlabel \" Experiment\", ylabel \"Travel time s \", label nothing, size 500, 250 , c gray md\"\"\" As we think of data as a set of random variables, we can plot the normalized histogram to roughly understand its probability density function. \"\"\" d1obs rand pdata1, 10000 sample some data from a given distribution begin pd1 histogram d1obs, normalize true, size 500, 250 , label nothing, xlabel \"Measurement\", c gray plot range 0.6, 1.4, step 0.01 , pdf. pdata1, range 0.6, 1.4, step 0.01 , w 2, label \"pdf\" vline 1.0 , w 3, c blue, label \"True Measurement\", margin 1cm end md\"\"\" The distribution of each of the random variables in the data is usually unknown, and may not be Normal as per the default choice below. For example, you may choose another one here bind pdata1 dist choices1 \"\"\" md\" Joint Probability Usually, our data are composed of multiple random variables. Independent if the conditional distribution is in. \" bind pdata2 dist choices1 d2obs rand pdata2, 10000 scatter2D d1obs, d2obs, 0.5, 1.5 , \"Independent Measurements\" md\"Are the elements of the data vector independent? Most likely not.\" A randn 2, 2 mixing matrix, lets call this op dmix mapslices x A x, hcat d1obs, d2obs , dims 2 scatter2D dmix , 1 , dmix , 2 , auto, \"Dependent Measurements\" md\" Coordinate Transformation\" plot histogram rand Uniform 0.5, 4 , 10000 , normalize true, label nothing, xlabel \"bulk modulus\", c gray, xlim 0, 5 , histogram inv. rand Uniform 0.5, 4 , 10000 , normalize true, label nothing, xlabel \"compressibility\", c gray , size 700, 300 , margin 1cm mrange range 0, 5, length 100 md\"\"\" Multi dimensional Gaussian Distribution ```math \\frac 1 \\sqrt 2\\pi \\mathrm det \\,C m \\,\\exp\\left \\frac 1 2 \\, m m 0 ^\\top\\,C m^ 1 \\, m m 0 \\right ``` \"\"\" pm2D MvNormal 3, 2 , Cₘ Cₘ 1 cov12 cov12 1 bind cov12 Slider range 0.7, stop 0.7, length 100 , show value true pheat2d mrange, mrange, Z, aspect ratio 1, title \"2 D Gaussian Density Function\" Z pdf pm2D, x, y for y in mrange, x in mrange md\"\"\" Marginal densities Given joint information about m 1 and m 2 , if we are only interested in one of the parameters, say m 1 , then we can marginalize over m 2 . ```math \\rho m 1 \\int m 2 \\rho m 1, m 2 \\,\\mathrm d m 2 ``` is the marginal probability density that contains all the information on m 1 that is independent of the information on m 2 . \"\"\" begin x, y rand Normal , 1000 , rand Uniform 10, 15 , 1000 layout layout a b 0.8w,0.8h c default plot layout layout, link both, size 500, 500 , margin 0.3cm scatter x, y, subplot 2, framestyle box, fillcolor lightgrey, markercolor gray, grid false, legend false, xlabel \"m₁\", ylabel \"m₂\" histogram x y , subplot 1 3 , orientation v h , framestyle none, label nothing, c gray end md\"\"\" Mean of measurements Consider the mean of measurements that were collected by repeating the experiment. What would be the distribution of the mean? You may slide to increase the number of independent experiments. \"\"\" bind d distribution Select Normal 1, 1 , Uniform 2, 2 bind nm Slider range 1, stop 25, step 1 , show value true dobs mean mean rand d distribution, 1000 for i in 1 nm begin histogram dobs mean, normalize true, size 500, 250 , label nothing, xlabel \"Measurement\", c gray, xlim 5, 5 vline 1.0 , w 3, c blue, label \"True Measurement\", margin 1cm, legend topleft end md\"\"\" Theoretical Information Θ d, m is the joint probability desnity describing the correlations that correspond to our physical theory , together with inherent uncertainites of the theory in this case, knowledge on the the outgoing wavenumber vector is uncertain, which is attributed to the raytracing \"\"\" md\"\"\" ```math \\Theta d, m \\theta d\\,|\\,m \\,μ m m ``` \"\"\" md\"\"\" ```math \\theta d\\,|\\,m \\text const. \\,\\exp\\left \\frac 1 2 \\, d g m ^\\top\\,C T^ 1 \\, d g m \\right ``` \"\"\" md\" Measurements\" md\"\"\" \\rho D d \"\"\" md\"\"\" Prior Information ```math \\rho M m ``` \"\"\" md\" Joint Prior Information ```math \\rho d, m \\rho D d \\,\\rho M m ```\" md\"\"\" Combining states of information Different experts or different datasets often provide different pieces of information that may be encoded by the probability densities ρ1 m and ρ2 m , respectively. ```math \\rho 1\\land\\rho 2 m k\\,\\frac \\rho 1 m \\rho 2 m \\rho h m ``` The homogeneous uninformative probability density in equation 3.47 ensures that the conjunction of information ρ1 with the no information ρh does not yield any new information, that is ```math \\rho 1 \\land \\rho h \\rho 1 ``` \"\"\" pm2D 1 MvNormal 1, 1 , 1 0 0 1 pm2D 2 MvNormal 3, 3 , 1 0.5 0.5 1 Z1 pdf pm2D 1, x, y for y in mrange, x in mrange Z2 pdf pm2D 2, x, y for y in mrange, x in mrange md\" Shannon's Measure\" md\"\"\" Appendix \"\"\" using PlutoUI, Plots, Distributions, Measures, PlutoTeachingTools, StatsPlots, Symbolics, LaTeXStrings, TikzPictures make a list of interesting distributions dist choices1 Select Normal 1, 0.1 \"Normal distribution\", Normal 1.1, 0.1 \"Normal with bias\", Uniform 0.9, 1.1 \"Uniform distribution ignorance \", Dirac 1.0 \"δ distribution perfect knowledge \" begin X range 8, 8, length 100 Y range 8, 8, length 100 end md\" Locate Source Experiment\" sxgrid range 2.0, stop 2.0, length 250 Tgrid range 0.95, 1.05, length 250 cex 5 velocity in km sec syms T 𝐱 𝐳 T expression sqrt abs2 𝐱 abs2 𝐳 inv cex get traveltime build function T expression, 𝐱, 𝐳 expression Val false sz expression sqrt abs2 cex T abs2 𝐱 return sz for a given T and sx get sz build function sz expression, T, 𝐱 expression Val false returns the derivative of sz w.r.t. T get dsz dT build function Symbolics.derivative sz expression, T , 𝐱, T expression Val false sz true 5.0 uncertainity in sz, with a fixed mean sz true pz Normal sex.μz, sex.σz theoretical information Θex broadcast Iterators.product sxgrid, Tgrid do sx, T pdf pz, get sz T, sx get dsz dT sx, T end prior information ρex broadcast Iterators.product sxgrid, Tgrid do sx, T pdf ρsx, sx pdf ρT, T end posterior information σex ρex . Θex prior on sx ρsx Normal sex.μx, sex.σx generate observed traveltime Tobs get traveltime sex.x, sz true Gaussian uncertainty for observed traveltime ρT Normal Tobs, sex.σT md\" UI\" function source loc ex input nsx length sxgrid nT length Tgrid return PlutoUI.combine do Child p md\"\"\" True x location of source Child \"x\", Slider range 1.5, stop 1.5, length 100 , default 1.2, show value true and known mean of z location Child \"μz\", Slider range 1, stop 5, length 100 , default 5, show value true \"\"\", σ md\"\"\" mean in x Child \"μx\", Slider sxgrid, default sxgrid div nsx,2 , show value true and standard deviation in x Child \"σx\", Slider range 0.05, stop 10, length 100 , default 10, show value true and standard deviation in z Child \"σz\", Slider range 0.001, stop .5, length 10 , default 0.05, show value true \"\"\", priorT md\"\"\" variance in observed traveltime Child \"σT\", Slider range 0.01, stop 0.5, length 100 , default 0.01, show value true \"\"\", md\"\"\" Locate The Source Consider a hypothetical experiment, where the x coordinate of the source has to be estimated given the P or S arrival travel time measured at a single receiver. Here, luckily, the z coordinate of the source has a known mean, and it has a given standard deviation True source location is p Prior information is assumed to be of Gaussian type with σ The uncertainty in the observed data has a standard deviation priorT \"\"\" end end md\" Plots\" begin userplot pheat2d recipe function f h pheat2d grid true size 500, 400 margin 2cm color amp seriestype contourf colorbar nothing series begin h.args end end end scatter2D d1, d2, lim auto, title \"\" scatter collect zip d1, d2 , xlabel \"Measurement 1\", ylabel \"Measurement 2\", label nothing, size 500, 500 , c gray, title title, lim lim, margin 1cm, framestyle box Θ plot pheat2d Tgrid, sxgrid, Θex, xlabel \"Travel time\", title \"Theoretical Information Θ d, m \" σ plot pheat2d Tgrid, sxgrid, σex, xlabel \"Travel time\", title \"Posterior Information σ d, m \" ρ plot pheat2d Tgrid, sxgrid, ρex, xlabel \"Travel time\", ylabel \"Source x location\", title \"Prior Information ρ d, m \" md\" Tikz\" tikz default options raw\"\"\" background rectangle .style fill white , show background rectangle, \"\"\" tikz preamble raw\"\"\" \\usepackage tikz \\usepackage tikz \\usetikzlibrary fit, matrix, shapes.geometric \\tikzset % use tikzset, not tikzstyle cell .style rectangle, rounded corners 5pt, draw, \\tikzset % use tikzset, not tikzstyle cellv .style rectangle, rounded corners 5pt, draw, rotate 90, \\usepackage xifthen \\usetikzlibrary hobby \\usepackage pgfplots \\usepackage fontawesome \\usepackage bm,amsfonts,amsmath \\usetikzlibrary backgrounds,pgfplots.groupplots,snakes \\usepgfplotslibrary patchplots \\pgfplotsset try min ticks 2 \\usepackage pgfplotstable \\usetikzlibrary plotmarks,positioning,spy \\usetikzlibrary shapes.geometric, arrows, fadings \\usepgfplotslibrary groupplots, polar \\usepackage space grffile \\usetikzlibrary % decorations.pathreplacing,% decorations.pathmorphing% \\usetikzlibrary positioning,fit,backgrounds \\usetikzlibrary shapes,arrows \\usetikzlibrary decorations.markings \\usetikzlibrary patterns \\usetikzlibrary plotmarks \\usetikzlibrary fit \\usetikzlibrary intersections \\usepgfplotslibrary fillbetween \\pgfplotsset axis line style black 10 , every axis label .append style black 10 , every axis title .append style black 10 , every tick label .append style black 10 % need for pgfplots \\newcommand \\axisz 0cm \\newcommand \\axisx 0cm \\usetikzlibrary positioning \\usetikzlibrary shapes.geometric \\usetikzlibrary backgrounds \"\"\" md\"\"\" References Mosegaard, Klaus, and Albert Tarantola. \"Probabilistic approach to inverse problems.\" International Geophysics Series 81.A 2002 237 268. Fichtner, Andreas. \"Lecture Notes on Inverse Theory.\" 2021 . \"\"\" "},{"url":"mod2_learning/tbu/","title":"To be updated","tags":["module2"],"text":"COMING SOON"},{"url":"mod3_time_series/tbu/","title":"To be updated","tags":["module3"],"text":"COMING SOON"}]